# -*- coding: utf-8 -*-
"""ftop2

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10JU_4BYcmKSJqnl_KoneZr27tKyEgzjm
"""

import cv2
import numpy as np
import matplotlib.pyplot as plt
import tkinter as tk
from tkinter import filedialog

# ============================
# CONFIGURACIÓN
# ============================
STEP = 2
MAX_SECONDS = None
SMOOTH_WINDOW = 9
Z_THRESH = 4.0
MIN_PERSIST = 6
ROI_MANUAL = None  # Ejemplo: (x, y, w, h) o None

# ============================
# SELECCIONAR VIDEO (WINDOWS)
# ============================
def pick_video():
    root = tk.Tk()
    root.withdraw()
    root.attributes("-topmost", True)

    path = filedialog.askopenfilename(
        title="Selecciona el video del reloj de yodo",
        filetypes=[("Video MP4", "*.mp4"), ("Todos los archivos", "*.*")]
    )
    root.destroy()

    if not path:
        raise RuntimeError("No se seleccionó ningún video")

    return path

# ============================
# REPRODUCIR VIDEO (FPS REAL + PAUSA)
# ============================
def play_video(video_path, roi=None):
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        raise ValueError("No se pudo abrir el video")

    fps = cap.get(cv2.CAP_PROP_FPS)
    if fps is None or fps <= 0 or np.isnan(fps):
        fps = 30.0  # respaldo

    wait = max(1, int(1000 / fps))  # ms por frame
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) or 0

    paused = False
    last_frame = None

    print(f"▶ Reproduciendo a ~{fps:.2f} FPS")
    print("Controles: ESPACIO pausa/reanuda | ← retrocede 1s | → adelanta 1s | ESC salir")

    while True:
        if not paused:
            ret, frame = cap.read()
            if not ret:
                break
            last_frame = frame
        else:
            # Si está pausado, seguimos mostrando el último frame
            frame = last_frame
            if frame is None:
                # si pausas antes de leer algo (raro), intenta leer
                ret, frame = cap.read()
                if not ret:
                    break
                last_frame = frame

        # Dibujar ROI si existe
        if roi is not None:
            x, y, w, h = roi
            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)

        # Mostrar info en pantalla (opcional)
        current_frame = int(cap.get(cv2.CAP_PROP_POS_FRAMES))
        t = current_frame / fps if fps > 0 else 0
        info = f"t={t:.2f}s  frame={current_frame}/{total_frames if total_frames else '?'}  {'PAUSA' if paused else ''}"
        cv2.putText(frame, info, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)

        cv2.imshow("Video - Reloj de Yodo", frame)

        key = cv2.waitKey(0 if paused else wait) & 0xFF

        # ESC
        if key == 27:
            break

        # ESPACIO (pausa/reanuda)
        if key == 32:
            paused = not paused
            continue

        # Flechas en OpenCV suelen llegar como códigos especiales dependiendo de Windows/teclado.
        # Usamos getKey con waitKey y manejamos los códigos comunes:
        # ← suele ser 81 o 2424832 (en algunos casos), → 83 o 2555904.
        # Como acá estamos con & 0xFF, a veces no llega. Mejor alternativa:
        # usar letras: 'a' retrocede, 'd' adelanta (más confiable).
        if key == ord('a'):  # retrocede 1s
            cur = cap.get(cv2.CAP_PROP_POS_FRAMES)
            cap.set(cv2.CAP_PROP_POS_FRAMES, max(0, cur - fps))
            paused = True  # queda pausado para ver
            continue

        if key == ord('d'):  # adelanta 1s
            cur = cap.get(cv2.CAP_PROP_POS_FRAMES)
            cap.set(cv2.CAP_PROP_POS_FRAMES, cur + fps)
            paused = True
            continue

    cap.release()
    cv2.destroyAllWindows()

# ============================
# MOSTRAR PRIMER FRAME (OPCIONAL)
# ============================
def preview_first_frame(video_path):
    cap = cv2.VideoCapture(video_path)
    ret, frame = cap.read()
    cap.release()

    if not ret:
        raise ValueError("No se pudo leer el primer frame")

    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    plt.figure(figsize=(8, 5))
    plt.imshow(frame_rgb)
    plt.title("Primer frame (para ubicar ROI si deseas)")
    plt.axis("off")
    plt.show()

# ============================
# ANÁLISIS COMPUTER VISION
# ============================
def extract_blue_signal(video_path, roi=None, step=2, max_seconds=None):
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        raise ValueError("No se pudo abrir el video")

    fps = cap.get(cv2.CAP_PROP_FPS)
    if fps <= 0 or np.isnan(fps):
        fps = 30.0

    ret, frame0 = cap.read()
    if not ret:
        raise ValueError("No se pudo leer el primer frame")

    H, W = frame0.shape[:2]

    if roi is None:
        rw, rh = int(0.55 * W), int(0.55 * H)
        x = (W - rw) // 2
        y = (H - rh) // 2
        roi = (x, y, rw, rh)

    cap.set(cv2.CAP_PROP_POS_FRAMES, 0)

    times, signal = [], []
    i = 0

    while True:
        ret, frame = cap.read()
        if not ret:
            break

        if i % step != 0:
            i += 1
            continue

        t = i / fps
        if max_seconds is not None and t > max_seconds:
            break

        x, y, rw, rh = roi
        crop = frame[y:y + rh, x:x + rw].astype(np.float32)

        B = crop[:, :, 0]
        G = crop[:, :, 1]
        R = crop[:, :, 2]

        bluish = (B - 0.5 * (R + G)).mean()
        times.append(t)
        signal.append(bluish)

        i += 1

    cap.release()
    return np.array(times), np.array(signal), fps, roi

def detect_switch_time(times, signal):
    kernel = np.ones(SMOOTH_WINDOW) / SMOOTH_WINDOW
    smooth = np.convolve(signal, kernel, mode="same")

    n0 = max(15, int(0.20 * len(smooth)))
    base = smooth[:n0]
    mu, sd = base.mean(), base.std() + 1e-9
    thr = mu + Z_THRESH * sd

    run = 0
    for i, v in enumerate(smooth):
        if v > thr:
            run += 1
            if run >= MIN_PERSIST:
                return times[i - MIN_PERSIST + 1], smooth, thr
        else:
            run = 0

    return np.nan, smooth, thr

# ============================
# MAIN
# ============================
print("=== RELOJ DE YODO - COMPUTER VISION ===")
VIDEO_PATH = pick_video()
print("Video seleccionado:", VIDEO_PATH)

# Reproduce video (FPS real + pausa)
play_video(VIDEO_PATH, ROI_MANUAL)

# (Opcional) mostrar primer frame (si no lo quieres, comenta la línea de abajo)
preview_first_frame(VIDEO_PATH)

# Analizar video
times, sig, fps, roi_used = extract_blue_signal(
    VIDEO_PATH,
    roi=ROI_MANUAL,
    step=STEP,
    max_seconds=MAX_SECONDS
)

t_d, sig_smooth, thr = detect_switch_time(times, sig)

print("\n============================")
print("RESULTADOS")
print("============================")
print("FPS:", fps)
print("ROI usado:", roi_used)
print("Tiempo de reacción t_d:", t_d, "s")

# Gráfica
plt.figure(figsize=(10, 4))
plt.plot(times, sig, label="Señal (raw)")
plt.plot(times, sig_smooth, label="Señal (suavizada)")
plt.axhline(thr, linestyle=":", label="Umbral")

if not np.isnan(t_d):
    plt.axvline(t_d, linestyle="--", label=f"t_d={t_d:.2f}s")

plt.xlabel("Tiempo (s)")
plt.ylabel("Señal azul-ness (B - (R+G)/2)")
plt.title("Detección automática de cambio a azul")
plt.legend()
plt.grid(True)
plt.show()

print("\nControles del reproductor:")
print(" - ESPACIO: pausa/reanuda")
print(" - a: retrocede 1 segundo (más confiable que flechas)")
print(" - d: adelanta 1 segundo (más confiable que flechas)")
print(" - ESC: salir")

#final del codigo
